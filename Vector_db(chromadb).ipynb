{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadi0004/Deep-Learning/blob/main/Vector_db(chromadb).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb google-generativeai sentence-transformers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJLRrc8DX0Ap",
        "outputId": "8c746092-a652-42bb-bce9-f52117ae7b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.1.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/664.8 MB\u001b[0m \u001b[31m171.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up our gemini api key"
      ],
      "metadata": {
        "id": "95fVfv9UX8Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ[\"Google_API_KEY\"] = \" \"\n",
        "genai.configure(api_key = os.getenv(\"Google_API_KEY\"))"
      ],
      "metadata": {
        "id": "vQBqMSGEYhLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Cromadb\n",
        "\n",
        "# import chromadb\n",
        "\n",
        "# # Initialize ChromaDB client (in-memory or persistent storage)\n",
        "# chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  # Persistent storage\n",
        "# # chroma_client = chromadb.Client()  # In-memory storage\n",
        "\n",
        "# # Create a new collection\n",
        "# collection = chroma_client.get_or_create_collection(name=\"gemini_embeddings\")\n"
      ],
      "metadata": {
        "id": "z3D85RIQYjpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "chroma_client = chromadb.PersistentClient(path = \"./chroma_db\")\n",
        "chroma_client = chromadb.Client()\n",
        "collection = chroma_client.get_or_create_collection(name=\"gemini_embeddings\")"
      ],
      "metadata": {
        "id": "ky-D-celY2Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Generate Text Embeddings using Sentence Transformers\n",
        "\n",
        "# Since Google Gemini does not provide direct embeddings, we use sentence-transformers to generate embeddings from text."
      ],
      "metadata": {
        "id": "fmjt8Q8yY3j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def generate_embedding(text):\n",
        "  return embedding_model.encode(text).tolist()"
      ],
      "metadata": {
        "id": "PDLsep-QZ4vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Insert Data into ChromaDB"
      ],
      "metadata": {
        "id": "T4E05QGkaAeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    {\"id\": \"1\", \"text\": \"What is machine learning?\"},\n",
        "    {\"id\": \"2\", \"text\": \"Explain deep learning and its applications.\"},\n",
        "    {\"id\": \"3\", \"text\": \"What are transformers in NLP?\"}\n",
        "]\n",
        "\n",
        "# Store documents with their embeddings\n",
        "for doc in documents:\n",
        "    embedding = generate_embedding(doc[\"text\"])\n",
        "    collection.add(\n",
        "        ids=[doc[\"id\"]],\n",
        "        embeddings=[embedding],\n",
        "        metadatas=[{\"text\": doc[\"text\"]}]\n",
        "    )\n",
        "\n",
        "print(\"Documents inserted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMhDO8P2akPr",
        "outputId": "610a200c-00ec-41bf-89c4-a6ccc5271544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents inserted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Query the Database (Semantic Search)\n",
        "\n",
        "# To retrieve similar documents, generate an embedding for the query and perform a nearest neighbor search."
      ],
      "metadata": {
        "id": "VmTt85TQa8Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query_text = \"Tell me about neural networks\"\n",
        "# query_embedding = generate_embedding(query_text)\n",
        "\n",
        "# # Perform similarity search\n",
        "# results = collection.query(\n",
        "#     query_embeddings=[query_embedding],\n",
        "#     n_results=2  # Number of closest matches\n",
        "# )\n",
        "\n",
        "# # Display search results\n",
        "# for i, result in enumerate(results[\"metadatas\"][0]):\n",
        "#     print(f\"Result {i+1}: {result['text']}\")\n"
      ],
      "metadata": {
        "id": "AYe5R8mxbSpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"Tell me What is ml\"\n",
        "query_embedding = generate_embedding(query_text)\n",
        "\n",
        "## Perform similar elements\n",
        "results = collection.query(\n",
        "    query_embeddings = [query_embedding],\n",
        "\n",
        "    n_results =2\n",
        ")\n",
        "\n",
        "for i , result in enumerate(results[\"metadatas\"][0]):\n",
        "  print(f\"Result {i+1}: {result['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpjZSOd6biu7",
        "outputId": "c554e9f9-5d74-4fab-a958-fad1eea3caae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result 1: What is machine learning?\n",
            "Result 2: Explain deep learning and its applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Use Google Gemini for Text Generation\n",
        "\n",
        "# You can use Google Gemini API to generate answers based on the retrieved documents."
      ],
      "metadata": {
        "id": "KRrQccExcDkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gemini_response(prompt):\n",
        "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Generate response based on retrieved data\n",
        "if results[\"metadatas\"][0]:\n",
        "    context = results[\"metadatas\"][0][0][\"text\"]\n",
        "    response = get_gemini_response(f\"Explain in detail: {context}\")\n",
        "    print(\"\\nAI Response:\\n\", response)\n",
        "else:\n",
        "    print(\"No relevant results found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HYgs8tCKeBbD",
        "outputId": "5be2ceb4-e7b3-4afc-a694-05afe56a983e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AI Response:\n",
            " ## Machine Learning: A Detailed Explanation\n",
            "\n",
            "Machine learning (ML) is a subfield of Artificial Intelligence (AI) that focuses on enabling computer systems to learn from data without being explicitly programmed.  Instead of relying on hardcoded rules, machine learning algorithms identify patterns, make predictions, and improve their performance over time as they are exposed to more data.\n",
            "\n",
            "**In essence, machine learning is about giving computers the ability to learn and adapt.**\n",
            "\n",
            "Here's a breakdown of key aspects:\n",
            "\n",
            "**1.  The Core Idea: Learning from Data**\n",
            "\n",
            "*   **Data-Driven Approach:**  ML algorithms derive knowledge and insights directly from data. This data can take many forms:\n",
            "    *   **Structured Data:**  Organized data stored in tables or databases with defined rows and columns (e.g., customer information, sales records).\n",
            "    *   **Unstructured Data:**  Data that doesn't have a predefined format (e.g., text, images, audio, video).\n",
            "*   **Pattern Recognition:**  The primary goal of many ML algorithms is to identify hidden patterns, correlations, and relationships within the data.  These patterns can be used for various purposes, such as predicting future events, classifying data points, or grouping similar items.\n",
            "*   **Improvement Over Time:**  The hallmark of ML is its ability to improve its performance as it processes more data. This learning process involves adjusting the algorithm's internal parameters to better capture the underlying patterns in the data.\n",
            "\n",
            "**2. Types of Machine Learning**\n",
            "\n",
            "Machine learning is typically categorized into several types based on the nature of the learning signal or the type of task being performed.  The most common types are:\n",
            "\n",
            "*   **Supervised Learning:**\n",
            "\n",
            "    *   **Definition:**  The algorithm learns from labeled data, where each data point is associated with a known output or target variable. The goal is to learn a mapping function that can predict the output for new, unseen data.\n",
            "    *   **Analogy:**  Learning with a teacher.  The teacher provides the correct answers (labels) during the learning process.\n",
            "    *   **Examples:**\n",
            "        *   **Classification:**  Predicting a categorical output (e.g., spam/not spam, cat/dog/bird).  Algorithms like Logistic Regression, Support Vector Machines (SVMs), and Decision Trees are used.\n",
            "        *   **Regression:**  Predicting a continuous output (e.g., house price, temperature, stock price).  Algorithms like Linear Regression, Polynomial Regression, and Random Forests are used.\n",
            "    *   **Key Steps:**\n",
            "        1.  **Data Collection:** Gather labeled data (features and corresponding labels).\n",
            "        2.  **Model Selection:** Choose an appropriate supervised learning algorithm.\n",
            "        3.  **Training:** Train the model using the labeled data. The algorithm adjusts its parameters to minimize the difference between predicted and actual labels.\n",
            "        4.  **Evaluation:** Evaluate the model's performance on a separate test dataset to assess its generalization ability (how well it performs on unseen data).\n",
            "        5.  **Deployment:**  Use the trained model to make predictions on new, unseen data.\n",
            "\n",
            "*   **Unsupervised Learning:**\n",
            "\n",
            "    *   **Definition:** The algorithm learns from unlabeled data, where there are no predefined output labels. The goal is to discover hidden structures, patterns, or relationships within the data.\n",
            "    *   **Analogy:**  Learning without a teacher. The algorithm must figure out the patterns on its own.\n",
            "    *   **Examples:**\n",
            "        *   **Clustering:**  Grouping similar data points together (e.g., customer segmentation, anomaly detection).  Algorithms like K-Means Clustering and Hierarchical Clustering are used.\n",
            "        *   **Dimensionality Reduction:**  Reducing the number of variables in the dataset while preserving important information (e.g., feature extraction, data visualization).  Algorithms like Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE) are used.\n",
            "        *   **Association Rule Mining:**  Discovering relationships between items in a dataset (e.g., market basket analysis, recommendation systems).  Algorithms like Apriori and Eclat are used.\n",
            "    *   **Key Steps:**\n",
            "        1.  **Data Collection:** Gather unlabeled data (features only).\n",
            "        2.  **Model Selection:** Choose an appropriate unsupervised learning algorithm.\n",
            "        3.  **Training:** Train the model using the unlabeled data. The algorithm explores the data and identifies patterns or structures.\n",
            "        4.  **Evaluation:** Evaluate the results based on the specific task.  Evaluation metrics often depend on the chosen algorithm and the goals of the analysis.\n",
            "        5.  **Interpretation:**  Interpret the results and extract meaningful insights from the discovered patterns.\n",
            "\n",
            "*   **Reinforcement Learning:**\n",
            "\n",
            "    *   **Definition:**  The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions.  The goal is to learn an optimal strategy (policy) that maximizes the cumulative reward over time.\n",
            "    *   **Analogy:**  Learning through trial and error. The algorithm explores different actions and learns from the consequences.\n",
            "    *   **Examples:**\n",
            "        *   **Game Playing:**  Training AI agents to play games like chess, Go, and video games.\n",
            "        *   **Robotics:**  Developing robots that can learn to navigate and interact with their environment.\n",
            "        *   **Control Systems:**  Optimizing control systems for various applications, such as robotics and resource management.\n",
            "    *   **Key Concepts:**\n",
            "        *   **Agent:** The learner or decision-maker.\n",
            "        *   **Environment:** The world the agent interacts with.\n",
            "        *   **Action:**  A move made by the agent in the environment.\n",
            "        *   **Reward:** A signal indicating the desirability of an action.\n",
            "        *   **State:** A description of the environment at a particular point in time.\n",
            "        *   **Policy:** A mapping from states to actions that the agent uses to choose its actions.\n",
            "\n",
            "*   **Semi-Supervised Learning:**\n",
            "\n",
            "    *   **Definition:** A combination of supervised and unsupervised learning.  The algorithm learns from a dataset that contains both labeled and unlabeled data. This approach is useful when labeling data is expensive or time-consuming.\n",
            "    *   **Use Case:** Useful when a small amount of labeled data is available with a large amount of unlabeled data.\n",
            "\n",
            "*   **Self-Supervised Learning:**\n",
            "\n",
            "    *   **Definition:** The algorithm learns by generating its own labels from the data itself. It extracts supervision signals from the inherent structure of the data and uses these signals to train a model.\n",
            "    *   **Example:** Training a language model to predict the next word in a sentence based on the preceding words.\n",
            "\n",
            "**3. The Machine Learning Process (General Steps)**\n",
            "\n",
            "While the specific steps may vary depending on the problem and the type of ML being used, the general process typically involves:\n",
            "\n",
            "1.  **Problem Definition:** Clearly define the problem you're trying to solve and the desired outcome.  What question are you trying to answer?  What prediction are you trying to make?\n",
            "2.  **Data Collection:** Gather relevant data.  Ensure the data is representative of the problem you're trying to solve and that it's of sufficient quality.\n",
            "3.  **Data Preprocessing:** Clean, transform, and prepare the data for training. This includes handling missing values, dealing with outliers, normalizing data, and feature engineering.\n",
            "4.  **Feature Engineering (Optional):**  Create new features or modify existing ones to improve the performance of the ML algorithm.  This often involves domain expertise.\n",
            "5.  **Model Selection:** Choose an appropriate ML algorithm based on the type of problem, the characteristics of the data, and the desired outcome.\n",
            "6.  **Training:** Train the model using the prepared data. The algorithm adjusts its internal parameters to learn the underlying patterns in the data.\n",
            "7.  **Evaluation:** Evaluate the model's performance using appropriate metrics. This involves testing the model on a separate dataset that it has never seen before.\n",
            "8.  **Hyperparameter Tuning:** Optimize the model's hyperparameters to improve its performance. Hyperparameters are parameters that are set before the training process begins.\n",
            "9.  **Deployment:**  Deploy the trained model to make predictions on new, unseen data.\n",
            "10. **Monitoring and Maintenance:** Continuously monitor the model's performance in the real world and retrain it as needed to maintain its accuracy and relevance.\n",
            "\n",
            "**4. Key Concepts and Techniques**\n",
            "\n",
            "*   **Algorithms:**  The specific mathematical procedures that are used to learn from data. Examples include linear regression, logistic regression, decision trees, support vector machines, neural networks, K-means clustering, and principal component analysis.\n",
            "*   **Features:**  The input variables that are used to train the model. These can be raw data points or engineered features.\n",
            "*   **Labels:**  The output variables that the model is trying to predict.  These are only used in supervised learning.\n",
            "*   **Model:**  A mathematical representation of the relationships between the input features and the output labels.\n",
            "*   **Training Data:** The data used to train the model.\n",
            "*   **Testing Data:** The data used to evaluate the model's performance on unseen data.\n",
            "*   **Overfitting:** When a model learns the training data too well and performs poorly on unseen data.\n",
            "*   **Underfitting:** When a model is too simple to capture the underlying patterns in the data.\n",
            "*   **Regularization:** Techniques used to prevent overfitting by adding a penalty to complex models.\n",
            "*   **Cross-Validation:** A technique used to evaluate the performance of a model on multiple subsets of the data.\n",
            "*   **Loss Function:** A function that measures the difference between the predicted and actual values.  The goal of training is to minimize the loss function.\n",
            "*   **Optimization:** The process of finding the values of the model's parameters that minimize the loss function.\n",
            "*   **Metrics:**  Quantitative measures used to evaluate the performance of a model. Examples include accuracy, precision, recall, F1-score, and AUC.\n",
            "\n",
            "**5. Applications of Machine Learning**\n",
            "\n",
            "Machine learning is being used in a wide range of industries and applications, including:\n",
            "\n",
            "*   **Healthcare:**  Diagnosis, drug discovery, personalized medicine.\n",
            "*   **Finance:**  Fraud detection, credit scoring, algorithmic trading.\n",
            "*   **Marketing:**  Customer segmentation, targeted advertising, recommendation systems.\n",
            "*   **Transportation:**  Self-driving cars, traffic optimization.\n",
            "*   **Retail:**  Inventory management, price optimization.\n",
            "*   **Manufacturing:**  Predictive maintenance, quality control.\n",
            "*   **Natural Language Processing (NLP):**  Machine translation, text summarization, chatbot development.\n",
            "*   **Computer Vision:**  Image recognition, object detection, video analysis.\n",
            "\n",
            "**6.  Benefits of Machine Learning**\n",
            "\n",
            "*   **Automation:**  Automates tasks that traditionally require human intelligence.\n",
            "*   **Improved Accuracy:**  Can often achieve higher accuracy than human experts in certain tasks.\n",
            "*   **Scalability:**  Can process large amounts of data quickly and efficiently.\n",
            "*   **Personalization:**  Can personalize experiences for individual users.\n",
            "*   **New Insights:**  Can uncover hidden patterns and relationships in data that humans may not be able to see.\n",
            "\n",
            "**7. Challenges of Machine Learning**\n",
            "\n",
            "*   **Data Requirements:**  Requires large amounts of high-quality data.\n",
            "*   **Computational Resources:**  Can be computationally expensive, especially for complex models.\n",
            "*   **Interpretability:**  Some models are difficult to interpret, making it hard to understand why they make certain predictions.  This is often referred to as the \"black box\" problem.\n",
            "*   **Bias:**  Models can be biased if the training data is biased.\n",
            "*   **Ethical Concerns:**  Raises ethical concerns about fairness, privacy, and security.\n",
            "*   **Maintenance:** Models require ongoing monitoring and retraining to maintain accuracy and relevance.\n",
            "\n",
            "**In summary, machine learning is a powerful tool that enables computers to learn from data and make predictions or decisions without explicit programming. It is a rapidly evolving field with the potential to transform many aspects of our lives.**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFqHaXozeUGL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
